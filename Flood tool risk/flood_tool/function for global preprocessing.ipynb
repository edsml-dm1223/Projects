{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes_labelled = pd.read_csv('flood_tool/resources/postcodes_labelled.csv')\n",
    "data = postcodes_labelled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postcode</th>\n",
       "      <th>easting</th>\n",
       "      <th>northing</th>\n",
       "      <th>soilType</th>\n",
       "      <th>elevation</th>\n",
       "      <th>nearestWatercourse</th>\n",
       "      <th>distanceToWatercourse</th>\n",
       "      <th>localAuthority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BA1 1AL</td>\n",
       "      <td>374813</td>\n",
       "      <td>164571</td>\n",
       "      <td>Unsurveyed/Urban</td>\n",
       "      <td>20</td>\n",
       "      <td>River Avon</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>Bath and North East Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BA1 1AN</td>\n",
       "      <td>375116</td>\n",
       "      <td>164500</td>\n",
       "      <td>Unsurveyed/Urban</td>\n",
       "      <td>20</td>\n",
       "      <td>River Avon</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>Bath and North East Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BA1 1AR</td>\n",
       "      <td>375091</td>\n",
       "      <td>164454</td>\n",
       "      <td>Unsurveyed/Urban</td>\n",
       "      <td>20</td>\n",
       "      <td>River Avon</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>Bath and North East Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA1 1BG</td>\n",
       "      <td>375060</td>\n",
       "      <td>164969</td>\n",
       "      <td>Unsurveyed/Urban</td>\n",
       "      <td>30</td>\n",
       "      <td>River Avon</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>Bath and North East Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BA1 1BH</td>\n",
       "      <td>375021</td>\n",
       "      <td>164930</td>\n",
       "      <td>Unsurveyed/Urban</td>\n",
       "      <td>30</td>\n",
       "      <td>River Avon</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>Bath and North East Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>W6 0XA</td>\n",
       "      <td>521911</td>\n",
       "      <td>178821</td>\n",
       "      <td>Unsurveyed/Urban</td>\n",
       "      <td>10</td>\n",
       "      <td>River Thames</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>Hounslow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>W6 0XY</td>\n",
       "      <td>521796</td>\n",
       "      <td>179018</td>\n",
       "      <td>Unsurveyed/Urban</td>\n",
       "      <td>10</td>\n",
       "      <td>River Thames</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Hounslow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>W6 0YE</td>\n",
       "      <td>521930</td>\n",
       "      <td>178998</td>\n",
       "      <td>Unsurveyed/Urban</td>\n",
       "      <td>10</td>\n",
       "      <td>River Thames</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>Hounslow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>WD3 1PZ</td>\n",
       "      <td>507392</td>\n",
       "      <td>191779</td>\n",
       "      <td>Planosols</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>Hillingdon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>WD3 2UX</td>\n",
       "      <td>504343</td>\n",
       "      <td>193039</td>\n",
       "      <td>Gleysols</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>470.0</td>\n",
       "      <td>Hillingdon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      postcode  easting  northing          soilType  elevation  \\\n",
       "0      BA1 1AL   374813    164571  Unsurveyed/Urban         20   \n",
       "1      BA1 1AN   375116    164500  Unsurveyed/Urban         20   \n",
       "2      BA1 1AR   375091    164454  Unsurveyed/Urban         20   \n",
       "3      BA1 1BG   375060    164969  Unsurveyed/Urban         30   \n",
       "4      BA1 1BH   375021    164930  Unsurveyed/Urban         30   \n",
       "...        ...      ...       ...               ...        ...   \n",
       "79995   W6 0XA   521911    178821  Unsurveyed/Urban         10   \n",
       "79996   W6 0XY   521796    179018  Unsurveyed/Urban         10   \n",
       "79997   W6 0YE   521930    178998  Unsurveyed/Urban         10   \n",
       "79998  WD3 1PZ   507392    191779         Planosols        100   \n",
       "79999  WD3 2UX   504343    193039          Gleysols         50   \n",
       "\n",
       "      nearestWatercourse  distanceToWatercourse                localAuthority  \n",
       "0             River Avon                 1240.0  Bath and North East Somerset  \n",
       "1             River Avon                 1550.0  Bath and North East Somerset  \n",
       "2             River Avon                 1540.0  Bath and North East Somerset  \n",
       "3             River Avon                 1450.0  Bath and North East Somerset  \n",
       "4             River Avon                 1410.0  Bath and North East Somerset  \n",
       "...                  ...                    ...                           ...  \n",
       "79995       River Thames                 1790.0                      Hounslow  \n",
       "79996       River Thames                 2020.0                      Hounslow  \n",
       "79997       River Thames                 1940.0                      Hounslow  \n",
       "79998                NaN                 1790.0                    Hillingdon  \n",
       "79999                NaN                  470.0                    Hillingdon  \n",
       "\n",
       "[80000 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=['medianPrice', 'riskLabel', 'historicallyFlooded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_soil_type = LabelEncoder()\n",
    "soil_type = le_soil_type.fit_transform(data['soilType'])\n",
    "data['soilType'] = soil_type\n",
    "le_nw = LabelEncoder()\n",
    "nearestWatercourse = le_nw.fit_transform(data['nearestWatercourse'])\n",
    "data['nearestWatercourse'] = nearestWatercourse\n",
    "local_aut = LabelEncoder()\n",
    "localAuthority = local_aut.fit_transform(data['localAuthority'])\n",
    "data['localAuthority'] = localAuthority\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def preprocess_begin(data):\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data['nearestWatercourse'].fillna(('NoStreamer', inplace=True))\n",
    "\n",
    "def imputer(column):\n",
    "    imputer = SimpleImputer(strategy='knn')\n",
    "    data[column] = imputer.fit_transform(data[column])\n",
    "    return data\n",
    "\n",
    "def create_lat_long_columns(data):\n",
    "    from geo import get_gps_lat_long_from_easting_northing\n",
    "    get_gps_lat_long_from_easting_northing(data['easting'], data['northing'])\n",
    "    coordinates_df = pd.DataFrame({\n",
    "        'Latitude': coordinates_lat[0],\n",
    "        'Longitude': coordinates_lat[1]\n",
    "    })\n",
    "    data = pd.concat([data, coordinates_df], axis=1)\n",
    "    data.drop(columns=['easting', 'northing'], inplace=True)\n",
    "    return data\n",
    "    \n",
    "def label_encode(column):\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    return data\n",
    "\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.Dataframe(data['latitude'], order = decreasing)\n",
    "sorted_latitude = data.sort_values(by = 'latitude', ascending=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "from sklnear.linear_model import LinearRegression\n",
    "lR = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# def take_district(postcodes):\n",
    "    \n",
    "    # def binning(column):\n",
    "#     if (column == 'medianPrice') or (column == 'distanceToWatercourse'):\n",
    "#         min_, lower, median, higher, max_ = np.log(data[col]).describe()[['min', '25%', '50%', '75%', 'max']]\n",
    "        \n",
    "#     else:\n",
    "#         min_, lower, median, higher, max_ = data[column].describe()[['min', '25%', '50%', '75%', 'max']]\n",
    "#     bins = [min_, lower, median, higher, max_]\n",
    "#     labels = ['Very Low', 'Low-Median', 'Median-high', 'High']\n",
    "#     return binning_column\n",
    "\n",
    "# def imputing(column):\n",
    "#     imputer = SimpleImputer(strategy='knn')\n",
    "#     data[column] = imputer.fit_transform(data[column])\n",
    "#     return data\n",
    "\n",
    "\n",
    "# Imputer = Pipeline([steps=\n",
    "# ('imputer', SimpleImputer(strategy='knn')),])\n",
    "\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "\n",
    "\n",
    "# log\n",
    "# Scaler = Pipeline(())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def interaction_term(column_1, column_2):\n",
    "\n",
    "#     data['interaction_term'] = data[column_1] * data[column_2]\n",
    "    \n",
    "#     data['log_medianPrice'] = np.log(data['medianPrice'])\n",
    "#     min_, lower, median, higher, max = data['log_medianPrice'].describe()[['min', '25%', '50%', '75%', 'max']]\n",
    "#     # Create bins for log-transformed medianPrice based on the description of log median price\n",
    "#     bins = [min, 25%, 50%, 75%, np.inf]\n",
    "#     labels = ['Low', 'Medium', 'High']\n",
    "\n",
    "#     # Apply log transformation and binning\n",
    "#     data['price_category'] = pd.cut(data['log_medianPrice'], bins=bins, labels=labels)\n",
    "#     # Display the first few rows to verify\n",
    "#     data[['medianPrice', 'log_medianPrice', 'price_category']].head()\n",
    "#     # postcodes_labelled.isnull().sum()\n",
    "\n",
    "#     #data['nearestWatercourse'].nunique() # 1146 + Nan which is No nearest WaterCourse\n",
    "#     data['nearestWatercourse'].fillna('NoStreamNear', inplace=True)\n",
    "\n",
    "#     ## Define bins and labels\n",
    "#     elevation_bins = [-10, 0, 40, 80, np.inf]\n",
    "#     elevation_labels = ['BelowSeaLevel', 'Low', 'Medium', 'High']\n",
    "#     # Apply binning to the elevation column\n",
    "#     data['elevation_category'] = pd.cut(data['elevation'], bins=elevation_bins, labels=elevation_labels)\n",
    "#     )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deluge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
