{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, FunctionTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from flood_tool.geo import get_gps_lat_long_from_easting_northing\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('flood_tool/resources/postcodes_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/qf5v72y97y709qmzdz43p2f00000gn/T/ipykernel_71334/3977225782.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['nearestWatercourse'].fillna('NoStreamNear', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "coordinates_lat = get_gps_lat_long_from_easting_northing(data['easting'], data['northing'])\n",
    "coordinates_df = pd.DataFrame({\n",
    "    'Latitude': coordinates_lat[0],\n",
    "    'Longitude': coordinates_lat[1]\n",
    "})\n",
    "data = pd.concat([data, coordinates_df], axis=1)\n",
    "data.drop(columns=['easting', 'northing'], inplace=True)\n",
    "\n",
    "data['log_medianPrice'] = np.log(data['medianPrice'])\n",
    "\n",
    "# Create bins for log-transformed medianPrice based on the description of log median price\n",
    "bins = [-np.inf, 11.9, 14.2, np.inf]\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "\n",
    "# Apply log transformation and binning\n",
    "data['price_category'] = pd.cut(data['log_medianPrice'], bins=bins, labels=labels)\n",
    "# Display the first few rows to verify\n",
    "data[['medianPrice', 'log_medianPrice', 'price_category']].head()\n",
    "# postcodes_labelled.isnull().sum()\n",
    "\n",
    "#data['nearestWatercourse'].nunique() # 1146 + Nan which is No nearest WaterCourse\n",
    "data['nearestWatercourse'].fillna('NoStreamNear', inplace=True)\n",
    "\n",
    "## Define bins and labels\n",
    "elevation_bins = [-10, 0, 40, 80, np.inf]\n",
    "elevation_labels = ['BelowSeaLevel', 'Low', 'Medium', 'High']\n",
    "# Apply binning to the elevation column\n",
    "data['elevation_category'] = pd.cut(data['elevation'], bins=elevation_bins, labels=elevation_labels)\n",
    "\n",
    "# Define bins and labels\n",
    "distance_bins = [0, 630, 1090, 1840, np.inf]\n",
    "distance_labels = ['Very Close', 'Close', 'Moderate', 'Far']\n",
    "\n",
    "# Apply binning to the distanceToWatercourse column\n",
    "data['distanceToWatercourse_category'] = pd.cut(data['distanceToWatercourse'], bins=distance_bins, labels=distance_labels)\n",
    "\n",
    "bins = [-np.inf, 11.9, 14.2, np.inf]\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "\n",
    "# Apply log transformation and binning\n",
    "data['log_medianPrice'] = np.log(data['medianPrice'])\n",
    "data['price_category'] = pd.cut(data['log_medianPrice'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(x):\n",
    "    return np.log1p(x+10)\n",
    "\n",
    "numeric_features = ['elevation', 'distanceToWatercourse']\n",
    "numeric_remained = ['Latitude', 'Longitude']\n",
    "categorical_features = ['soilType']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log_transform', FunctionTransformer(log_transform, validate=True)),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "numeric_remained_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('num_rem', numeric_remained_transformer, numeric_remained),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "standard_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X include soilType, nearestWatercourse, elevation, distanceToWatercourse, Latitude, Longitude\n",
    "# y include riskLabel\n",
    "\n",
    "X = data[['elevation', 'distanceToWatercourse', 'Latitude', 'Longitude', 'soilType']]\n",
    "y = data['riskLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall ROC AUC: 0.8617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.94      0.85     15876\n",
      "           2       0.69      0.36      0.47      4165\n",
      "           3       0.46      0.28      0.35      2134\n",
      "           4       0.60      0.44      0.51       628\n",
      "           5       0.56      0.27      0.36       730\n",
      "           6       0.16      0.26      0.20       314\n",
      "           7       0.14      0.22      0.17       153\n",
      "\n",
      "    accuracy                           0.73     24000\n",
      "   macro avg       0.48      0.39      0.42     24000\n",
      "weighted avg       0.72      0.73      0.71     24000\n",
      "\n",
      "Class 1 ROC AUC: 0.8325\n",
      "Class 2 ROC AUC: 0.7942\n",
      "Class 3 ROC AUC: 0.8757\n",
      "Class 4 ROC AUC: 0.8903\n",
      "Class 5 ROC AUC: 0.8859\n",
      "Class 6 ROC AUC: 0.8539\n",
      "Class 7 ROC AUC: 0.8994\n"
     ]
    }
   ],
   "source": [
    "# enconde y to 0, 1, 2, 3, 4, 5, 6\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_transformed = standard_pipeline.fit_transform(X_train)\n",
    "X_test_transformed = standard_pipeline.transform(X_test)\n",
    "\n",
    "# imbalanced data handling (SMOTE and ADASYN)\n",
    "smote = SMOTE(sampling_strategy={5: 5000, 6: 2000}, random_state=42)\n",
    "adasyn = ADASYN(sampling_strategy={5: 6000, 6: 3000}, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_transformed, y_train)\n",
    "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# data augmentation for class 6 and 7\n",
    "X_train_class6 = X_train_transformed[y_train == 5]\n",
    "X_train_class7 = X_train_transformed[y_train == 6]\n",
    "noise6 = np.random.normal(0, 0.01, X_train_class6.shape)\n",
    "noise7 = np.random.normal(0, 0.01, X_train_class7.shape)\n",
    "X_augmented = np.vstack([X_train_class6 + noise6, X_train_class7 + noise7])\n",
    "y_augmented = np.hstack([np.full(X_train_class6.shape[0], 5), np.full(X_train_class7.shape[0], 6)])\n",
    "\n",
    "X_train_resampled = np.vstack([X_train_resampled, X_augmented])\n",
    "y_train_resampled = np.hstack([y_train_resampled, y_augmented])\n",
    "\n",
    "# calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "XGboost = XGBClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "XGboost.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# predict and decode\n",
    "y_pred_proba = XGboost.predict_proba(X_test_transformed)\n",
    "y_pred_encoded = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# set threshold for class 6 and 7\n",
    "threshold_6 = 0.3\n",
    "threshold_7 = 0.3\n",
    "y_pred_encoded[(y_pred_proba[:, 5] > threshold_6)] = 5\n",
    "y_pred_encoded[(y_pred_proba[:, 6] > threshold_7)] = 6\n",
    "\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "y_test_original = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "print(f'Overall ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "print(classification_report(y_test_original, y_pred))\n",
    "\n",
    "for i, cls in enumerate(label_encoder.classes_):\n",
    "    cls_roc_auc = roc_auc_score((y_test == i).astype(int), y_pred_proba[:, i])\n",
    "    print(f\"Class {cls} ROC AUC: {cls_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best parameters: {'learning_rate': 0.5, 'max_depth': 9, 'n_estimators': 400}\n",
      "Overall ROC AUC: 0.8403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.89      0.84     15876\n",
      "           2       0.57      0.42      0.48      4165\n",
      "           3       0.43      0.36      0.40      2134\n",
      "           4       0.52      0.40      0.45       628\n",
      "           5       0.46      0.28      0.35       730\n",
      "           6       0.16      0.25      0.19       314\n",
      "           7       0.15      0.21      0.18       153\n",
      "\n",
      "    accuracy                           0.72     24000\n",
      "   macro avg       0.44      0.40      0.41     24000\n",
      "weighted avg       0.70      0.72      0.70     24000\n",
      "\n",
      "Class 1 ROC AUC: 0.8165\n",
      "Class 2 ROC AUC: 0.7730\n",
      "Class 3 ROC AUC: 0.8611\n",
      "Class 4 ROC AUC: 0.8635\n",
      "Class 5 ROC AUC: 0.8627\n",
      "Class 6 ROC AUC: 0.8252\n",
      "Class 7 ROC AUC: 0.8805\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "param_distributions = {\n",
    "    'n_estimators': [200, 300, 400, 500, 600],\n",
    "    'max_depth': randint(3, 15),\n",
    "    'learning_rate': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier with other parameters fixed\n",
    "xgb = XGBClassifier(\n",
    "    random_state=42,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=5,\n",
    "    scoring='roc_auc_ovr',\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Retrain the model with the best parameters\n",
    "XGboost = XGBClassifier(\n",
    "    random_state=42,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='mlogloss',\n",
    "    **best_params\n",
    ")\n",
    "XGboost.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and decode\n",
    "y_pred_proba = XGboost.predict_proba(X_test_transformed)\n",
    "y_pred_encoded = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Set threshold for classes 5 and 6\n",
    "threshold_5 = 0.3\n",
    "threshold_6 = 0.3\n",
    "y_pred_encoded[(y_pred_proba[:, 5] > threshold_5)] = 5\n",
    "y_pred_encoded[(y_pred_proba[:, 6] > threshold_6)] = 6\n",
    "\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "y_test_original = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "print(f'Overall ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "print(classification_report(y_test_original, y_pred))\n",
    "\n",
    "for i, cls in enumerate(label_encoder.classes_):\n",
    "    cls_roc_auc = roc_auc_score((y_test == i).astype(int), y_pred_proba[:, i])\n",
    "    print(f\"Class {cls} ROC AUC: {cls_roc_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npp2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
